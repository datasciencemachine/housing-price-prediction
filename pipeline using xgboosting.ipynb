{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was a part of a kaggle challenge which was able to get a public score of 15865.38007 and was able to secure a rank in top 11.13% or a percentile  88.86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "train=pd.read_csv('train.csv', index_col='Id')\n",
    "X_original = train\n",
    "test = pd.read_csv('test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "y=train['SalePrice']\n",
    "X_original=train.drop(['SalePrice'], axis=1)\n",
    "obj=X_original.select_dtypes(include=object).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECTING COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be label encoded: ['Street', 'Alley', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'RoofStyle', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'CentralAir', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageCond', 'PavedDrive', 'Fence', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['MiscFeature', 'Functional', 'RoofMatl', 'Heating', 'Electrical', 'SaleType', 'HouseStyle', 'MSZoning', 'Exterior1st', 'GarageQual', 'PoolQC', 'KitchenQual', 'Exterior2nd', 'Utilities', 'Condition2']\n"
     ]
    }
   ],
   "source": [
    "good_label_cols = [col for col in obj if \n",
    "                   set(train[col]) == set(test[col])]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(obj)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "obj=good_label_cols\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "hot_cols = [cname for cname in obj if\n",
    "                    X_original[cname].nunique() < 10 ]\n",
    "\n",
    "#select categorical columns with high cardinality\n",
    "ordinary_cols = [cname for cname in obj if\n",
    "                    X_original[cname].nunique() >= 10 ] \n",
    "        \n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_original if \n",
    "                X_original[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "my_cols = hot_cols + ordinary_cols + numerical_cols\n",
    "#X_train,X_val,y_train,y_val=train_test_split(X_original,y,random_state=0)\n",
    "\n",
    "#selecting only required cooumns\n",
    "#X_train=X_train[my_cols]\n",
    "#X_val=X_val[my_cols]\n",
    "X=X_original[my_cols]\n",
    "test=test[my_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING TRANSFORMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer=SimpleImputer(strategy='constant')\n",
    "hot_transformer=Pipeline(steps=[('imputer',SimpleImputer(strategy='constant')),\n",
    "                                ('Encoder',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "ord_transformer=Pipeline(steps=[('imputer',SimpleImputer(strategy='constant')),\n",
    "                                ('Encoder',OrdinalEncoder(dtype='float64'))])\n",
    "\n",
    "Preprocessor=ColumnTransformer(transformers=[('numerical',num_transformer,numerical_cols),\n",
    "                                             ('ord',ord_transformer,ordinary_cols),\n",
    "                                             ('hot',hot_transformer,hot_cols)])\n",
    "\n",
    "scale=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1=xgb.XGBRegressor(max_depth=2,n_estimators=400,n_jobs=-1,reg_lambda=2,reg_alpha=6)\n",
    "pipeline1=Pipeline(steps=[('preprocessing',Preprocessor),\n",
    "                          ('scale',scale),\n",
    "                         ('model',model1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numerical',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='constant',\n",
       "                                                                verbose=0),\n",
       "                                                  ['MSSubClass', 'LotFrontage',\n",
       "                                                   'LotArea', 'OverallQual',\n",
       "                                                   'OverallCond', 'YearBuil...\n",
       "                              interaction_constraints='',\n",
       "                              learning_rate=0.300000012, max_delta_step=0,\n",
       "                              max_depth=2, min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=400,\n",
       "                              n_jobs=-1, num_parallel_tree=1,\n",
       "                              objective='reg:squarederror', random_state=0,\n",
       "                              reg_alpha=6, reg_lambda=2, scale_pos_weight=1,\n",
       "                              subsample=1, tree_method='exact',\n",
       "                              validate_parameters=1, verbosity=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline1.fit(X,y)\n",
    "#pred=pipeline1.predict(X_val)\n",
    "#mean_absolute_error(pred,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pipeline1.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': test.index, 'SalePrice': pred})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
